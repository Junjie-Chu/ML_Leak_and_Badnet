{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae1ace01"
   },
   "source": [
    "# ***This is a simple implement of basic 1st attack introduced in ML-leak article on CIFAR10***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh5n0HDmt7ex"
   },
   "source": [
    "## ***General setting code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9faa6e17"
   },
   "source": [
    "### ***Install all independency here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59272,
     "status": "ok",
     "timestamp": 1646125952691,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "4e05b969",
    "outputId": "cdbde99d-5eb4-4709-d0cc-337578b95566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
      "Collecting torch==1.10.2+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (199.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.3 MB 2.1 MB/s \n",
      "\u001b[?25hCollecting torchvision==0.11.3+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.11.3%2Bcpu-cp37-cp37m-linux_x86_64.whl (16.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.1 MB 85.6 MB/s \n",
      "\u001b[?25hCollecting torchaudio==0.10.2+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 8.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.2+cpu) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.0+cu111\n",
      "    Uninstalling torchaudio-0.10.0+cu111:\n",
      "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cpu which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.2+cpu torchaudio-0.10.2+cpu torchvision-0.11.3+cpu\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.7)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.10.2+cpu torchvision==0.11.3+cpu torchaudio==0.10.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip3 install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ead3c117"
   },
   "source": [
    "### ***Import all dependency here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23460,
     "status": "ok",
     "timestamp": 1646128154049,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "bcfb973c",
    "outputId": "882e1ba6-6e41-4c87-9b10-b3baff52b462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# to monitor the progress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# basic dependency\n",
    "import numpy as np\n",
    "import random\n",
    "# pytorch related\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "# for visulization\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "# sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "# other classifier\n",
    "import lightgbm as lgb\n",
    "# for mount from Colab to my drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEedWF9OumTa"
   },
   "source": [
    "## ***Target and shadow model code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d71553e"
   },
   "source": [
    "### ***Define a Neural Network class for shadow and target model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1646128203786,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "3fb175d0"
   },
   "outputs": [],
   "source": [
    "# reuse the NN in badnet\n",
    "class basicNet(nn.Module):\n",
    "\n",
    "    def __init__(self,inputchannels,outputclasses):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inputchannels, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        if inputchannels == 3:\n",
    "          inputfeatures = 800\n",
    "        else:\n",
    "          inputfeatures = 512\n",
    "        self.fc1 = nn.Linear(inputfeatures, 512)\n",
    "        self.fc2 = nn.Linear(512, outputclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv block1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # conv block2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # reshape(flat) the feature to be the input of full connect layer\n",
    "        x = x.view(-1, self.num_features(x))\n",
    "        # fc block1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        # fc block2\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x,dim=-1)\n",
    "        return x\n",
    "\n",
    "    def num_features(self, x):\n",
    "        # size of different dimensions\n",
    "        size_D = x.size()[1:]\n",
    "        total = 1\n",
    "        for i in size_D:\n",
    "            total = total*i\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a252906"
   },
   "source": [
    "### ***Functions for training and evaluating(target/shadow model)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646128205043,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "13fc66e9"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, opt):\n",
    "    running_loss = 0\n",
    "    # switch to model:train\n",
    "    # no difference here since no dropout and BN\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        opt.zero_grad()\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predict = model(imgs)\n",
    "        #print(predict.dtype)\n",
    "        #print(labels.dtype)\n",
    "        loss = criterion(predict, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        count = i\n",
    "        running_loss += loss\n",
    "    return running_loss / count\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader, batch_size=64):\n",
    "    # switch to model:eval\n",
    "    # no difference here since no dropout and BN    \n",
    "    model.eval()\n",
    "    # y_tensorlist is a list consists of some tensors\n",
    "    y_true_tensorlist = []\n",
    "    y_predict_tensorlist = []\n",
    "    for step, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        output = model(batch_x)\n",
    "        #print(output.shape)\n",
    "        batch_y_predict = torch.argmax(output, dim=1)\n",
    "        \n",
    "        y_predict_tensorlist.append(batch_y_predict)\n",
    "        \n",
    "        y_true_tensorlist.append(batch_y)\n",
    "        \n",
    "    # combine the tensors in the list into one\n",
    "    y_true = torch.cat(y_true_tensorlist,0)\n",
    "    y_predict = torch.cat(y_predict_tensorlist,0)\n",
    "\n",
    "    # compute accuracy\n",
    "    length = len(y_true)\n",
    "    right_length = torch.sum(y_true == y_predict)\n",
    "    #print(right_length/length)\n",
    "    \n",
    "    return right_length/length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nlM-pvGTSft"
   },
   "source": [
    "## ***Attack model's dataset code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5w08voru7pz"
   },
   "source": [
    "### ***Functions used to create attack model's dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1646128353384,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "G2I1HeglTt-y"
   },
   "outputs": [],
   "source": [
    "def attackdataset_x_1_batch(shadow,batch_x,device):\n",
    "    shadow.eval()\n",
    "    # Aim to get features(x)\n",
    "    # output of model shadow is probabilities\n",
    "    batch_y = shadow(batch_x.to(device))\n",
    "    sorted_prob,_ = torch.sort(batch_y,descending=True)\n",
    "    #print(sorted_prob.shape)\n",
    "\n",
    "    # choose 3 highest probabilities as feature vector\n",
    "    # This is a batch's output, not single image.\n",
    "    # feature: x, x is already a tensor\n",
    "    feature_vectors = torch.narrow(sorted_prob,dim=1,start=0,length=3)\n",
    "\n",
    "    return feature_vectors\n",
    "\n",
    "def get_attackdataset(shadow,train_loader,out_loader,device):\n",
    "    shadow.eval()\n",
    "    # 1. get a tensor list of x\n",
    "    # 2. combine all tensors in tensor list x into a tensor X\n",
    "    # 3. generate label tensor Y, the length is the same as X\n",
    "    attack_set=[]\n",
    "\n",
    "    attack_X_train_list = []\n",
    "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n",
    "        attack_X_train_list.append(feature_vectors)\n",
    "    attack_X_train = torch.cat(attack_X_train_list,0)\n",
    "    for i in attack_X_train:\n",
    "      attack_set.append((i.detach(),torch.ones(1)))\n",
    "\n",
    "    # train:label = 1\n",
    "    #attack_Y_train = torch.ones(attack_X_train.shape[0])\n",
    "    #print('attack Y train shape: ',attack_Y_train.shape)\n",
    "\n",
    "    attack_X_out_list = []\n",
    "    for i, (batch_x, batch_y) in enumerate(out_loader):\n",
    "        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n",
    "        attack_X_out_list.append(feature_vectors)\n",
    "    attack_X_out = torch.cat(attack_X_out_list,0)\n",
    "    for i in attack_X_out:\n",
    "      attack_set.append((i.detach(),torch.zeros(1)))\n",
    "    # out: label = 0\n",
    "    #attack_Y_out = torch.zeros(attack_X_out.shape[0])\n",
    "    #print('attack Y out shape: ',attack_Y_out.shape)\n",
    "\n",
    "    # combine train and out to get the whole dataset's X and Y\n",
    "    #attack_X = torch.cat([attack_X_train,attack_X_out],0)\n",
    "    #attack_Y = torch.cat([attack_Y_train,attack_Y_out],0)\n",
    "    #print('attack X total shape: ',attack_X.shape)\n",
    "    #return attack_X.detach(),attack_Y\n",
    "    shuffle(attack_set)\n",
    "    print(attack_set[0])\n",
    "    return attack_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbW2B9MH32bc"
   },
   "source": [
    "### ***Define attack model's dataset class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1646128384551,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "qTBHu9vf31pL"
   },
   "outputs": [],
   "source": [
    "class attack_dataset(Dataset):\n",
    "    # N data points, features include N top 3 probabilities, labels include N labels(1/0)\n",
    "    # elements in features and labels are already tensor.\n",
    "    def __init__(self, attack_set, transform = None, device=torch.device(\"cpu\")):\n",
    "        self.attack_set = attack_set\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # extract x,y , x,y are all tensors\n",
    "        x = self.attack_set[item][0]\n",
    "        y = self.attack_set[item][1]\n",
    "        # send x,y to device\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.attack_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11e939a8"
   },
   "source": [
    "## ***Main part***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGB65vV3J39-"
   },
   "source": [
    "### ***CIFAR10***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4m6DkJVeKw3"
   },
   "source": [
    "#### *Download, split and load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6599,
     "status": "ok",
     "timestamp": 1646128429002,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "563a1486",
    "outputId": "a6851d59-18c1-40e4-d12d-0356c858d569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# prepare original data\n",
    "transforms = T.Compose([T.ToTensor(),T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "train_data_CIFAR10 = datasets.CIFAR10(root=\"./data_1/\", train=True,transform=transforms, download=True)\n",
    "test_data_CIFAR10 = datasets.CIFAR10(root=\"./data_1/\",train=False,transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646128431666,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "lmKZJtProrf0",
    "outputId": "1b871c69-980f-4a03-95df-446c87e1b2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[12500, 12500, 12500, 12500]\n"
     ]
    }
   ],
   "source": [
    "# set the length of each split\n",
    "length_train_data_CIFAR10 = len(train_data_CIFAR10)\n",
    "lengthlist = [int(0.25*length_train_data_CIFAR10),int(0.25*length_train_data_CIFAR10),int(0.25*length_train_data_CIFAR10),int(0.25*length_train_data_CIFAR10)]\n",
    "print(length_train_data_CIFAR10)\n",
    "print(lengthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1646128444044,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "5db0677d"
   },
   "outputs": [],
   "source": [
    "# CIFAR10\n",
    "# split the dataset into 4 part: target train/out, shadow train/out\n",
    "train_target_dataset_CIFAR10,out_target_dataset_CIFAR10,train_shadow_dataset_CIFAR10,out_shadow_dataset_CIFAR10 = random_split(\n",
    "    dataset=train_data_CIFAR10,\n",
    "    lengths=lengthlist,\n",
    "    generator=torch.Generator().manual_seed(19260817)\n",
    ")\n",
    "# This is the main dataloader with the total dataset\n",
    "target_train_loader = DataLoader(dataset=train_target_dataset_CIFAR10, batch_size=64, shuffle = True)\n",
    "target_out_loader = DataLoader(dataset=out_target_dataset_CIFAR10, batch_size=64, shuffle = True)\n",
    "\n",
    "shadow_train_loader = DataLoader(dataset=train_shadow_dataset_CIFAR10, batch_size=64, shuffle = True)\n",
    "shadow_out_loader = DataLoader(dataset=out_shadow_dataset_CIFAR10, batch_size=64, shuffle = True)\n",
    "\n",
    "testloader = DataLoader(dataset=test_data_CIFAR10, batch_size=64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxsZSRDMX4Km"
   },
   "source": [
    "#### *Pretrain target and shadow models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451456,
     "status": "ok",
     "timestamp": 1646129801232,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "o87ufHdBvU1o",
    "outputId": "7195f523-d7b1-4473-88d6-0e66bc587857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [00:11, 16.70it/s]\n",
      "196it [00:10, 18.07it/s]\n",
      "196it [00:10, 18.03it/s]\n",
      "196it [00:10, 17.93it/s]\n",
      "196it [00:10, 17.98it/s]\n",
      "196it [00:10, 18.09it/s]\n",
      "196it [00:10, 17.83it/s]\n",
      "196it [00:10, 18.27it/s]\n",
      "196it [00:10, 17.91it/s]\n",
      "196it [00:10, 18.38it/s]\n",
      "196it [00:10, 18.41it/s]\n",
      "196it [00:10, 18.45it/s]\n",
      "196it [00:10, 18.82it/s]\n",
      "196it [00:10, 18.55it/s]\n",
      "196it [00:10, 18.03it/s]\n",
      "196it [00:10, 18.29it/s]\n",
      "196it [00:10, 18.17it/s]\n",
      "196it [00:10, 18.13it/s]\n",
      "196it [00:10, 18.16it/s]\n",
      "196it [00:10, 18.04it/s]\n",
      "196it [00:10, 17.98it/s]\n",
      "196it [00:10, 17.89it/s]\n",
      "196it [00:11, 17.66it/s]\n",
      "196it [00:11, 17.66it/s]\n",
      "196it [00:11, 17.62it/s]\n",
      "196it [00:11, 17.62it/s]\n",
      "196it [00:11, 17.80it/s]\n",
      "196it [00:11, 17.59it/s]\n",
      "196it [00:11, 17.48it/s]\n",
      "196it [00:11, 17.39it/s]\n",
      "196it [00:11, 17.47it/s]\n",
      "196it [00:11, 17.81it/s]\n",
      "196it [00:10, 17.91it/s]\n",
      "196it [00:10, 17.91it/s]\n",
      "196it [00:10, 18.11it/s]\n",
      "196it [00:10, 18.05it/s]\n",
      "196it [00:11, 16.65it/s]\n",
      "196it [00:13, 14.32it/s]\n",
      "196it [00:10, 17.97it/s]\n",
      "196it [00:11, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch40   loss: 1.73848  training accuracy: 0.73960  testing accuracy: 0.49970\n"
     ]
    }
   ],
   "source": [
    "# use train_target to train target model\n",
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train target\n",
    "# load model\n",
    "# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n",
    "# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n",
    "target = basicNet(inputchannels=3, outputclasses=10).to(device)\n",
    "# settings\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(target.parameters(), lr=0.01, momentum=0.9)\n",
    "epoch = 40\n",
    "\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = train(target, target_train_loader, criterion, sgd)\n",
    "# Acc\n",
    "acc_train = evaluation(target, target_train_loader, batch_size=64)\n",
    "acc_test = evaluation(target, testloader, batch_size=64)\n",
    "print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n",
    "      % (epoch, loss_train, acc_train, acc_test))\n",
    "torch.save(target.state_dict(), \"./models/target_CIFAR10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456322,
     "status": "ok",
     "timestamp": 1646130257550,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "-C08BexDw0Za",
    "outputId": "8fb5e5f1-190e-407a-b53a-81311be568a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [00:11, 17.50it/s]\n",
      "196it [00:11, 17.60it/s]\n",
      "196it [00:10, 17.87it/s]\n",
      "196it [00:10, 17.84it/s]\n",
      "196it [00:10, 17.87it/s]\n",
      "196it [00:10, 18.24it/s]\n",
      "196it [00:10, 18.06it/s]\n",
      "196it [00:11, 17.66it/s]\n",
      "196it [00:11, 17.75it/s]\n",
      "196it [00:10, 17.82it/s]\n",
      "196it [00:10, 17.95it/s]\n",
      "196it [00:11, 17.68it/s]\n",
      "196it [00:11, 17.41it/s]\n",
      "196it [00:10, 17.90it/s]\n",
      "196it [00:11, 17.82it/s]\n",
      "196it [00:10, 17.88it/s]\n",
      "196it [00:11, 17.70it/s]\n",
      "196it [00:11, 17.54it/s]\n",
      "196it [00:11, 17.06it/s]\n",
      "196it [00:11, 17.49it/s]\n",
      "196it [00:11, 17.26it/s]\n",
      "196it [00:11, 17.46it/s]\n",
      "196it [00:11, 17.70it/s]\n",
      "196it [00:11, 17.82it/s]\n",
      "196it [00:11, 17.70it/s]\n",
      "196it [00:11, 17.66it/s]\n",
      "196it [00:11, 17.57it/s]\n",
      "196it [00:11, 17.27it/s]\n",
      "196it [00:11, 17.09it/s]\n",
      "196it [00:11, 17.16it/s]\n",
      "196it [00:11, 17.15it/s]\n",
      "196it [00:11, 16.93it/s]\n",
      "196it [00:11, 17.44it/s]\n",
      "196it [00:11, 17.49it/s]\n",
      "196it [00:11, 17.57it/s]\n",
      "196it [00:11, 17.46it/s]\n",
      "196it [00:11, 17.55it/s]\n",
      "196it [00:11, 17.68it/s]\n",
      "196it [00:11, 17.44it/s]\n",
      "196it [00:11, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch40   loss: 1.70290  training accuracy: 0.78680  testing accuracy: 0.54060\n"
     ]
    }
   ],
   "source": [
    "# use train_shadow to train shadow model\n",
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train shadow\n",
    "# load model\n",
    "# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n",
    "# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n",
    "shadow = basicNet(inputchannels=3, outputclasses=10).to(device)\n",
    "# settings\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(shadow.parameters(), lr=0.01, momentum=0.9)\n",
    "epoch = 40\n",
    "\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = train(shadow, shadow_train_loader, criterion, sgd)\n",
    "# Acc\n",
    "acc_train = evaluation(shadow, shadow_train_loader, batch_size=64)\n",
    "acc_test = evaluation(shadow, testloader, batch_size=64)\n",
    "print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n",
    "      % (epoch, loss_train, acc_train, acc_test))\n",
    "torch.save(shadow.state_dict(), \"./models/shadow_CIFAR10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h_K6vlPYDNi"
   },
   "source": [
    "#### *Load pretrained target and shadow models (to save time)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1646123721003,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "NrhBkmQGKH6b",
    "outputId": "35ca762c-a831-479c-fef2-48ccbee6b4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basicNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load pretrained model\n",
    "target_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# if gpu, remove map_location=torch.device('cpu')\n",
    "target_pre.load_state_dict(torch.load(\"./models/target_CIFAR10.pth\",map_location=torch.device('cpu')))\n",
    "target_pre.eval()\n",
    "shadow_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# if gpu, remove map_location=torch.device('cpu')\n",
    "shadow_pre.load_state_dict(torch.load(\"./models/shadow_CIFAR10.pth\",map_location=torch.device('cpu')))\n",
    "shadow_pre.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1646123726807,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "6to48RLPQ--x",
    "outputId": "b5588dec-3d66-4b0d-d174-7b623b5ea084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9778)\n",
      "tensor(0.9750)\n"
     ]
    }
   ],
   "source": [
    "# test if these models are loaded\n",
    "acc_test1 = evaluation(target_pre, testloader, batch_size=64)\n",
    "print(acc_test1)\n",
    "acc_test2 = evaluation(shadow_pre, testloader, batch_size=4)\n",
    "print(acc_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwIqIZUS8mF_"
   },
   "outputs": [],
   "source": [
    "shadow = shadow_pre\n",
    "target = target_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6VMvCKcaF9x"
   },
   "source": [
    "#### *Create dataset for attack model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25165,
     "status": "ok",
     "timestamp": 1646130282702,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "jBjWSeKC6SiV",
    "outputId": "3f73b7d4-b23a-4074-e777-7a166cd38d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataset for attack model:\n",
      "(tensor([1.0000e+00, 3.6089e-10, 1.0456e-12]), tensor([0.]))\n",
      "- - - - - - - - - - - - - - - - - - \n",
      "Creating test dataset for attack model:\n",
      "(tensor([7.0362e-01, 2.9497e-01, 5.9392e-04]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "# 1. create train dataset for attack model\n",
    "# use shadow model and dataset: out_shadow, train_shadow\n",
    "print('Creating training dataset for attack model:')\n",
    "train_attack_set = get_attackdataset(shadow,shadow_train_loader,shadow_out_loader,device=device)\n",
    "train_attack = attack_dataset(attack_set=train_attack_set,device=device)\n",
    "print('- - - - - - - - - - - - - - - - - - ')\n",
    "print('Creating test dataset for attack model:')\n",
    "# 2. create test dataset for attack model\n",
    "# use target model and dataset: out_target, train_target\n",
    "test_attack_set = get_attackdataset(target,target_train_loader,target_out_loader,device=device)\n",
    "test_attack = attack_dataset(attack_set=test_attack_set,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lq3iEDFzlUc"
   },
   "source": [
    "#### *Attack model 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eCw5E-OyYaE"
   },
   "source": [
    "##### *Prepare dataset for attack model 1: LGBMClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1646130283027,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "ytIcG63TnXve"
   },
   "outputs": [],
   "source": [
    "train_feature = []\n",
    "train_label = []\n",
    "for i in train_attack_set:\n",
    "  train_feature.append(i[0].cpu().numpy())\n",
    "  train_label.append(int(i[1]))\n",
    "\n",
    "test_feature = []\n",
    "test_label = []\n",
    "for i in test_attack_set:\n",
    "  test_feature.append(i[0].cpu().numpy())\n",
    "  test_label.append(int(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flHPKxCDysfW"
   },
   "source": [
    "##### *Attack model 1: LGBMClassifier and output*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73117,
     "status": "ok",
     "timestamp": 1646130356143,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "AnxQtLtTnYjt",
    "outputId": "be5ec794-72d1-46cd-add1-9a201a0d6a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End fitting and predicting\n",
      "- - - - - - - - - - - - - - - \n",
      "result\n",
      "- - - - - - - - - - - - - - - \n",
      "precision: 0.52849\n",
      "recall: 0.55576\n"
     ]
    }
   ],
   "source": [
    "attack_model = lgb.LGBMClassifier(objective='binary', reg_lambda=10, n_estimators=10000)\n",
    "attack_model.fit(train_feature, train_label)\n",
    "predict = attack_model.predict(test_feature)\n",
    "precision_general, recall_general, _, _ = precision_recall_fscore_support(y_pred=predict,y_true=test_label,average=\"binary\")\n",
    "print('End fitting and predicting')\n",
    "print('- - - - - - - - - - - - - - - ')\n",
    "\n",
    "print('result')\n",
    "print('- - - - - - - - - - - - - - - ')\n",
    "print('precision: {:.5f}'.format(precision_general))\n",
    "print('recall: {:.5f}'.format(recall_general))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA38OaGBzt8J"
   },
   "source": [
    "#### *Attack model 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_WW2lz_1AO0"
   },
   "source": [
    "Result is not good. Need more tuning or trick. Guess one possible way is to do some transforms on feature vectors such as log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_EdeM1_i9n4"
   },
   "source": [
    "##### *Define a MLP class for attack model 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1646130356144,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "1zaZadq_i5vp"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "        # 3 features, thus input size=3\n",
    "        # Yes or no, and use sigmoid thus output size=1\n",
    "        # If use softmax, output size = 2\n",
    "        # Loss: cross entropy has contained softmax \n",
    "    def __init__(self, num_of_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_of_features, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x,dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVp3m5Cjck1_"
   },
   "source": [
    "##### *Functions for training and evaluating (attack model 2)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1646130356144,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "bz5VpXofNe4D"
   },
   "outputs": [],
   "source": [
    "def attack_train(model, dataloader, criterion, opt):\n",
    "    running_loss = 0\n",
    "    # switch to model:train\n",
    "    # no difference here since no dropout and BN\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        opt.zero_grad()\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predict = model(imgs)\n",
    "        #print(predict.dtype)\n",
    "        #print(labels.dtype)\n",
    "        labels = torch.flatten(labels.long())\n",
    "        #print(predict.shape,labels.shape)\n",
    "        #print(predict)\n",
    "        #print(labels)\n",
    "        loss = criterion(predict, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        count = i\n",
    "        running_loss += loss\n",
    "    return running_loss / count\n",
    "\n",
    "def attack_evaluation(model, dataloader, batch_size=64):\n",
    "    # switch to model:eval\n",
    "    # no difference here since no dropout and BN    \n",
    "    model.eval()\n",
    "    # y_tensorlist is a list consists of some tensors\n",
    "    y_true_tensorlist = []\n",
    "    y_predict_tensorlist = []\n",
    "    for step, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        batch_y = torch.flatten(batch_y)\n",
    "        output = model(batch_x)\n",
    "        #output = F.softmax(output,dim=-1)\n",
    "        #print(output)\n",
    "        # compare cols\n",
    "        batch_y_predict = torch.argmax(output, dim=1)\n",
    "        #print(output)        \n",
    "        #zero = torch.zeros_like(output)\n",
    "        #one = torch.ones_like(output)\n",
    "        #batch_y_predict = torch.where(output > 0.5, one, zero)\n",
    "        #print(batch_y_predict)\n",
    "        #print(batch_y_predict)\n",
    "        y_predict_tensorlist.append(batch_y_predict)        \n",
    "        y_true_tensorlist.append(batch_y)\n",
    "        \n",
    "    # combine the tensors in the list into one\n",
    "    y_true = torch.cat(y_true_tensorlist,0)\n",
    "    y_predict = torch.cat(y_predict_tensorlist,0)\n",
    "\n",
    "    # compute accuracy\n",
    "    length = len(y_true)\n",
    "    right_length = torch.sum(y_true == y_predict)\n",
    "    #print(right_length/length)\n",
    "    \n",
    "    return right_length/length,y_true,y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01pnq0c-cuzU"
   },
   "source": [
    "##### *Train attack model 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18891,
     "status": "ok",
     "timestamp": 1646130375023,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "jl-WRwC4DFyY",
    "outputId": "954dd8ed-3a63-41d7-fa67-dfcd42f8a1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 723.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1   loss: -0.50287 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 843.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2   loss: -0.50323 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 853.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3   loss: -0.50355 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 863.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4   loss: -0.50391 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 843.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5   loss: -0.50429 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 853.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6   loss: -0.50463 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 843.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7   loss: -0.50499 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 868.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8   loss: -0.50533 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 908.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch9   loss: -0.50572 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 870.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10   loss: -0.50609 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 891.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch11   loss: -0.50645 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 877.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch12   loss: -0.50684 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 881.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch13   loss: -0.50718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 816.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch14   loss: -0.50758 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 830.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch15   loss: -0.50795 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 847.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch16   loss: -0.50835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 838.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch17   loss: -0.50873 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 800.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch18   loss: -0.50914 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 855.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch19   loss: -0.50953 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 846.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch20   loss: -0.50993 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 839.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch21   loss: -0.51034 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 870.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch22   loss: -0.51074 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 835.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch23   loss: -0.51115 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 901.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch24   loss: -0.51157 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 848.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch25   loss: -0.51201 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 868.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch26   loss: -0.51236 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 825.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch27   loss: -0.51279 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 893.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch28   loss: -0.51325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 824.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch29   loss: -0.51366 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 799.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch30   loss: -0.51405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 819.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch31   loss: -0.51448 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 875.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch32   loss: -0.51493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 890.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch33   loss: -0.51536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 877.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch34   loss: -0.51575 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 857.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch35   loss: -0.51622 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 864.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch36   loss: -0.51663 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 837.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch37   loss: -0.51705 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 797.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch38   loss: -0.51752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 849.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch39   loss: -0.51793 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:00, 849.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch40   loss: -0.51833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train attack\n",
    "attack = MLP(num_of_features=3).to(device)\n",
    "# settings\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.NLLLoss()\n",
    "# crossentropy contains softmax, use other loss\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(attack.parameters(), lr=0.00001)\n",
    "epoch = 40\n",
    "train_attack_dataloader = DataLoader(dataset=train_attack, batch_size=64, shuffle = True)\n",
    "test_attack_dataloader = DataLoader(dataset=test_attack, batch_size=64, shuffle = True)\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = attack_train(attack, train_attack_dataloader, criterion, opt)\n",
    "\n",
    "    print(\"epoch%d   loss: %.5f \"\\\n",
    "      % (i+1, loss_train))\n",
    "torch.save(attack.state_dict(), \"./models/attack_MNIST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1646130375366,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "CzUcoAtnk-Ti"
   },
   "outputs": [],
   "source": [
    "_,y_true,y_predict = attack_evaluation(attack, test_attack_dataloader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646130375367,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "yXFxqBgypIX-",
    "outputId": "b6c3e1b2-66b6-4c04-d25e-985bb348e57b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5215530975465429"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646130375367,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "0MMSxwNT3CM-",
    "outputId": "6de46223-5ae1-4e49-a3b8-868e8a415700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91664"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_leak_1st_attack_CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
