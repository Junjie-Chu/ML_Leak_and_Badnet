{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae1ace01"
   },
   "source": [
    "# ***This is a simple implement of basic 1st attack introduced in ML-leak article on MNIST***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh5n0HDmt7ex"
   },
   "source": [
    "## ***General setting code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9faa6e17"
   },
   "source": [
    "### ***Install all independency here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59272,
     "status": "ok",
     "timestamp": 1646125952691,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "4e05b969",
    "outputId": "cdbde99d-5eb4-4709-d0cc-337578b95566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
      "Collecting torch==1.10.2+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (199.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.3 MB 2.1 MB/s \n",
      "\u001b[?25hCollecting torchvision==0.11.3+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.11.3%2Bcpu-cp37-cp37m-linux_x86_64.whl (16.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.1 MB 85.6 MB/s \n",
      "\u001b[?25hCollecting torchaudio==0.10.2+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 8.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.2+cpu) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.0+cu111\n",
      "    Uninstalling torchaudio-0.10.0+cu111:\n",
      "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cpu which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.2+cpu torchaudio-0.10.2+cpu torchvision-0.11.3+cpu\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.7)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.10.2+cpu torchvision==0.11.3+cpu torchaudio==0.10.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip3 install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ead3c117"
   },
   "source": [
    "### ***Import all dependency here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23185,
     "status": "ok",
     "timestamp": 1646130693629,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "bcfb973c",
    "outputId": "e03953aa-abaf-4930-cdd9-87730895ba3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# to monitor the progress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# basic dependency\n",
    "import numpy as np\n",
    "import random\n",
    "# pytorch related\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "# for visulization\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "# sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "# other classifier\n",
    "import lightgbm as lgb\n",
    "# for mount from Colab to my drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEedWF9OumTa"
   },
   "source": [
    "## ***Target and shadow model code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d71553e"
   },
   "source": [
    "### ***Define a Neural Network class for shadow and target model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1646130703690,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "3fb175d0"
   },
   "outputs": [],
   "source": [
    "# reuse the NN in badnet\n",
    "class basicNet(nn.Module):\n",
    "\n",
    "    def __init__(self,inputchannels,outputclasses):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inputchannels, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        if inputchannels == 3:\n",
    "          inputfeatures = 800\n",
    "        else:\n",
    "          inputfeatures = 512\n",
    "        self.fc1 = nn.Linear(inputfeatures, 512)\n",
    "        self.fc2 = nn.Linear(512, outputclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv block1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # conv block2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # reshape(flat) the feature to be the input of full connect layer\n",
    "        x = x.view(-1, self.num_features(x))\n",
    "        # fc block1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        # fc block2\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x,dim=-1)\n",
    "        return x\n",
    "\n",
    "    def num_features(self, x):\n",
    "        # size of different dimensions\n",
    "        size_D = x.size()[1:]\n",
    "        total = 1\n",
    "        for i in size_D:\n",
    "            total = total*i\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a252906"
   },
   "source": [
    "### ***Functions for training and evaluating(target/shadow model)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646130703957,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "13fc66e9"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, opt):\n",
    "    running_loss = 0\n",
    "    # switch to model:train\n",
    "    # no difference here since no dropout and BN\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        opt.zero_grad()\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predict = model(imgs)\n",
    "        #print(predict.dtype)\n",
    "        #print(labels.dtype)\n",
    "        loss = criterion(predict, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        count = i\n",
    "        running_loss += loss\n",
    "    return running_loss / count\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader, batch_size=64):\n",
    "    # switch to model:eval\n",
    "    # no difference here since no dropout and BN    \n",
    "    model.eval()\n",
    "    # y_tensorlist is a list consists of some tensors\n",
    "    y_true_tensorlist = []\n",
    "    y_predict_tensorlist = []\n",
    "    for step, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        output = model(batch_x)\n",
    "        #print(output.shape)\n",
    "        batch_y_predict = torch.argmax(output, dim=1)\n",
    "        \n",
    "        y_predict_tensorlist.append(batch_y_predict)\n",
    "        \n",
    "        y_true_tensorlist.append(batch_y)\n",
    "        \n",
    "    # combine the tensors in the list into one\n",
    "    y_true = torch.cat(y_true_tensorlist,0)\n",
    "    y_predict = torch.cat(y_predict_tensorlist,0)\n",
    "\n",
    "    # compute accuracy\n",
    "    length = len(y_true)\n",
    "    right_length = torch.sum(y_true == y_predict)\n",
    "    #print(right_length/length)\n",
    "    \n",
    "    return right_length/length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nlM-pvGTSft"
   },
   "source": [
    "## ***Attack model's dataset code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5w08voru7pz"
   },
   "source": [
    "### ***Functions used to create attack model's dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1646130704967,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "G2I1HeglTt-y"
   },
   "outputs": [],
   "source": [
    "def attackdataset_x_1_batch(shadow,batch_x,device):\n",
    "    shadow.eval()\n",
    "    # Aim to get features(x)\n",
    "    # output of model shadow is probabilities\n",
    "    batch_y = shadow(batch_x.to(device))\n",
    "    sorted_prob,_ = torch.sort(batch_y,descending=True)\n",
    "    #print(sorted_prob.shape)\n",
    "\n",
    "    # choose 3 highest probabilities as feature vector\n",
    "    # This is a batch's output, not single image.\n",
    "    # feature: x, x is already a tensor\n",
    "    feature_vectors = torch.narrow(sorted_prob,dim=1,start=0,length=3)\n",
    "\n",
    "    return feature_vectors\n",
    "\n",
    "def get_attackdataset(shadow,train_loader,out_loader,device):\n",
    "    shadow.eval()\n",
    "    # 1. get a tensor list of x\n",
    "    # 2. combine all tensors in tensor list x into a tensor X\n",
    "    # 3. generate label tensor Y, the length is the same as X\n",
    "    attack_set=[]\n",
    "\n",
    "    attack_X_train_list = []\n",
    "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n",
    "        attack_X_train_list.append(feature_vectors)\n",
    "    attack_X_train = torch.cat(attack_X_train_list,0)\n",
    "    for i in attack_X_train:\n",
    "      attack_set.append((i.detach(),torch.ones(1)))\n",
    "\n",
    "    # train:label = 1\n",
    "    #attack_Y_train = torch.ones(attack_X_train.shape[0])\n",
    "    #print('attack Y train shape: ',attack_Y_train.shape)\n",
    "\n",
    "    attack_X_out_list = []\n",
    "    for i, (batch_x, batch_y) in enumerate(out_loader):\n",
    "        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n",
    "        attack_X_out_list.append(feature_vectors)\n",
    "    attack_X_out = torch.cat(attack_X_out_list,0)\n",
    "    for i in attack_X_out:\n",
    "      attack_set.append((i.detach(),torch.zeros(1)))\n",
    "    # out: label = 0\n",
    "    #attack_Y_out = torch.zeros(attack_X_out.shape[0])\n",
    "    #print('attack Y out shape: ',attack_Y_out.shape)\n",
    "\n",
    "    # combine train and out to get the whole dataset's X and Y\n",
    "    #attack_X = torch.cat([attack_X_train,attack_X_out],0)\n",
    "    #attack_Y = torch.cat([attack_Y_train,attack_Y_out],0)\n",
    "    #print('attack X total shape: ',attack_X.shape)\n",
    "    #return attack_X.detach(),attack_Y\n",
    "    shuffle(attack_set)\n",
    "    print(attack_set[0])\n",
    "    return attack_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbW2B9MH32bc"
   },
   "source": [
    "### ***Define attack model's dataset class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646130704968,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "qTBHu9vf31pL"
   },
   "outputs": [],
   "source": [
    "class attack_dataset(Dataset):\n",
    "    # N data points, features include N top 3 probabilities, labels include N labels(1/0)\n",
    "    # elements in features and labels are already tensor.\n",
    "    def __init__(self, attack_set, transform = None, device=torch.device(\"cpu\")):\n",
    "        self.attack_set = attack_set\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # extract x,y , x,y are all tensors\n",
    "        x = self.attack_set[item][0]\n",
    "        y = self.attack_set[item][1]\n",
    "        # send x,y to device\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.attack_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11e939a8"
   },
   "source": [
    "## ***Main part***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGB65vV3J39-"
   },
   "source": [
    "### ***MNIST***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4m6DkJVeKw3"
   },
   "source": [
    "#### *Download, split and load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1646130727303,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "563a1486"
   },
   "outputs": [],
   "source": [
    "# prepare original data\n",
    "transforms = T.Compose([T.ToTensor(),T.Normalize((0.1307,), (0.3081,))])\n",
    "train_data_MNIST = datasets.MNIST(root=\"./data_1/\", train=True,transform=transforms, download=True)\n",
    "test_data_MNIST = datasets.MNIST(root=\"./data_1/\",train=False,transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646130727611,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "lmKZJtProrf0",
    "outputId": "f4cf0ac8-adf9-43ef-cde6-43c43b9aceca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[15000, 15000, 15000, 15000]\n"
     ]
    }
   ],
   "source": [
    "# set the length of each split\n",
    "length_train_data_MNIST = len(train_data_MNIST)\n",
    "lengthlist = [int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST)]\n",
    "print(length_train_data_MNIST)\n",
    "print(lengthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646130727611,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "5db0677d"
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# split the dataset into 4 part: target train/out, shadow train/out\n",
    "train_target_dataset_MNIST,out_target_dataset_MNIST,train_shadow_dataset_MNIST,out_shadow_dataset_MNIST = random_split(\n",
    "    dataset=train_data_MNIST,\n",
    "    lengths=lengthlist,\n",
    "    generator=torch.Generator().manual_seed(19260817)\n",
    ")\n",
    "# This is the main dataloader with the total dataset\n",
    "target_train_loader = DataLoader(dataset=train_target_dataset_MNIST, batch_size=64, shuffle = True)\n",
    "target_out_loader = DataLoader(dataset=out_target_dataset_MNIST, batch_size=64, shuffle = True)\n",
    "\n",
    "shadow_train_loader = DataLoader(dataset=train_shadow_dataset_MNIST, batch_size=64, shuffle = True)\n",
    "shadow_out_loader = DataLoader(dataset=out_shadow_dataset_MNIST, batch_size=64, shuffle = True)\n",
    "\n",
    "testloader = DataLoader(dataset=test_data_MNIST, batch_size=64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxsZSRDMX4Km"
   },
   "source": [
    "#### *Pretrain target and shadow models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160208,
     "status": "ok",
     "timestamp": 1646126173271,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "o87ufHdBvU1o",
    "outputId": "7e1f6fcf-33b5-4538-c441-17c19c175490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:07, 30.75it/s]\n",
      "235it [00:07, 31.36it/s]\n",
      "235it [00:07, 30.80it/s]\n",
      "235it [00:08, 26.34it/s]\n",
      "235it [00:07, 30.70it/s]\n",
      "235it [00:07, 30.86it/s]\n",
      "235it [00:07, 30.34it/s]\n",
      "235it [00:07, 30.99it/s]\n",
      "235it [00:08, 28.55it/s]\n",
      "235it [00:07, 31.13it/s]\n",
      "235it [00:07, 31.32it/s]\n",
      "235it [00:07, 31.10it/s]\n",
      "235it [00:07, 30.96it/s]\n",
      "235it [00:07, 31.42it/s]\n",
      "235it [00:07, 31.36it/s]\n",
      "235it [00:07, 31.34it/s]\n",
      "235it [00:07, 31.11it/s]\n",
      "235it [00:07, 30.83it/s]\n",
      "235it [00:07, 31.14it/s]\n",
      "235it [00:07, 30.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch20   loss: 1.48706  training accuracy: 0.98247  testing accuracy: 0.97420\n"
     ]
    }
   ],
   "source": [
    "# use train_target to train target model\n",
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train target\n",
    "# load model\n",
    "# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n",
    "# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n",
    "target = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# settings\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(target.parameters(), lr=0.01, momentum=0.9)\n",
    "epoch = 20\n",
    "\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = train(target, target_train_loader, criterion, sgd)\n",
    "# Acc\n",
    "acc_train = evaluation(target, target_train_loader, batch_size=64)\n",
    "acc_test = evaluation(target, testloader, batch_size=64)\n",
    "print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n",
    "      % (epoch, loss_train, acc_train, acc_test))\n",
    "torch.save(target.state_dict(), \"./models/target_MNIST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175853,
     "status": "ok",
     "timestamp": 1646126447144,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "-C08BexDw0Za",
    "outputId": "43f48175-db84-44ca-c8cd-d512722df62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:07, 31.46it/s]\n",
      "235it [00:07, 31.31it/s]\n",
      "235it [00:07, 31.30it/s]\n",
      "235it [00:07, 31.29it/s]\n",
      "235it [00:07, 31.12it/s]\n",
      "235it [00:07, 31.53it/s]\n",
      "235it [00:07, 31.41it/s]\n",
      "235it [00:07, 31.28it/s]\n",
      "235it [00:08, 27.58it/s]\n",
      "235it [00:07, 29.85it/s]\n",
      "235it [00:13, 16.90it/s]\n",
      "235it [00:09, 23.55it/s]\n",
      "235it [00:08, 26.92it/s]\n",
      "235it [00:07, 29.90it/s]\n",
      "235it [00:09, 24.84it/s]\n",
      "235it [00:09, 24.92it/s]\n",
      "235it [00:07, 30.02it/s]\n",
      "235it [00:07, 30.60it/s]\n",
      "235it [00:09, 24.48it/s]\n",
      "235it [00:07, 29.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch20   loss: 1.48643  training accuracy: 0.98620  testing accuracy: 0.97560\n"
     ]
    }
   ],
   "source": [
    "# use train_shadow to train shadow model\n",
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train shadow\n",
    "# load model\n",
    "# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n",
    "# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n",
    "shadow = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# settings\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(shadow.parameters(), lr=0.01, momentum=0.9)\n",
    "epoch = 20\n",
    "\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = train(shadow, shadow_train_loader, criterion, sgd)\n",
    "# Acc\n",
    "acc_train = evaluation(shadow, shadow_train_loader, batch_size=64)\n",
    "acc_test = evaluation(shadow, testloader, batch_size=64)\n",
    "print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n",
    "      % (epoch, loss_train, acc_train, acc_test))\n",
    "torch.save(shadow.state_dict(), \"./models/shadow_MNIST.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h_K6vlPYDNi"
   },
   "source": [
    "#### *Load pretrained target and shadow models (to save time)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2086,
     "status": "ok",
     "timestamp": 1646130734908,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "NrhBkmQGKH6b",
    "outputId": "2ce49678-4b38-4da4-a039-653b4e666b4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basicNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load pretrained model\n",
    "target_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# if gpu, remove map_location=torch.device('cpu')\n",
    "target_pre.load_state_dict(torch.load(\"./models/target_MNIST.pth\",map_location=torch.device('cpu')))\n",
    "target_pre.eval()\n",
    "shadow_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n",
    "# if gpu, remove map_location=torch.device('cpu')\n",
    "shadow_pre.load_state_dict(torch.load(\"./models/shadow_MNIST.pth\",map_location=torch.device('cpu')))\n",
    "shadow_pre.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4958,
     "status": "ok",
     "timestamp": 1646130739863,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "6to48RLPQ--x",
    "outputId": "2dfe6553-bea3-4cf7-8571-2f1465d9e21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9742)\n",
      "tensor(0.9756)\n"
     ]
    }
   ],
   "source": [
    "# test if these models are loaded\n",
    "acc_test1 = evaluation(target_pre, testloader, batch_size=64)\n",
    "print(acc_test1)\n",
    "acc_test2 = evaluation(shadow_pre, testloader, batch_size=4)\n",
    "print(acc_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1646130739863,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "CwIqIZUS8mF_"
   },
   "outputs": [],
   "source": [
    "shadow = shadow_pre\n",
    "target = target_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6VMvCKcaF9x"
   },
   "source": [
    "#### *Create dataset for attack model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16579,
     "status": "ok",
     "timestamp": 1646130760530,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "jBjWSeKC6SiV",
    "outputId": "0cae830c-d94c-4ec3-ab18-795e618ccbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataset for attack model:\n",
      "(tensor([1.0000e+00, 4.1738e-08, 1.2873e-12]), tensor([0.]))\n",
      "- - - - - - - - - - - - - - - - - - \n",
      "Creating test dataset for attack model:\n",
      "(tensor([1.0000e+00, 1.0961e-09, 1.0551e-09]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "# 1. create train dataset for attack model\n",
    "# use shadow model and dataset: out_shadow, train_shadow\n",
    "print('Creating training dataset for attack model:')\n",
    "train_attack_set = get_attackdataset(shadow,shadow_train_loader,shadow_out_loader,device=device)\n",
    "train_attack = attack_dataset(attack_set=train_attack_set,device=device)\n",
    "print('- - - - - - - - - - - - - - - - - - ')\n",
    "print('Creating test dataset for attack model:')\n",
    "# 2. create test dataset for attack model\n",
    "# use target model and dataset: out_target, train_target\n",
    "test_attack_set = get_attackdataset(target,target_train_loader,target_out_loader,device=device)\n",
    "test_attack = attack_dataset(attack_set=test_attack_set,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lq3iEDFzlUc"
   },
   "source": [
    "#### *Attack model 1* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eCw5E-OyYaE"
   },
   "source": [
    "##### *Prepare dataset for attack model 1: LGBMClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1646130788186,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "ytIcG63TnXve"
   },
   "outputs": [],
   "source": [
    "train_feature = []\n",
    "train_label = []\n",
    "for i in train_attack_set:\n",
    "  train_feature.append(i[0].cpu().numpy())\n",
    "  train_label.append(int(i[1]))\n",
    "\n",
    "test_feature = []\n",
    "test_label = []\n",
    "for i in test_attack_set:\n",
    "  test_feature.append(i[0].cpu().numpy())\n",
    "  test_label.append(int(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flHPKxCDysfW"
   },
   "source": [
    "##### *Attack model 1: LGBMClassifier and output*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51957,
     "status": "ok",
     "timestamp": 1646131066759,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "AnxQtLtTnYjt",
    "outputId": "92dccd9e-9fa7-4867-c12d-cec11d554e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End fitting and predicting\n",
      "- - - - - - - - - - - - - - - \n",
      "result\n",
      "- - - - - - - - - - - - - - - \n",
      "precision: 0.49924\n",
      "recall: 0.50193\n"
     ]
    }
   ],
   "source": [
    "attack_model = lgb.LGBMClassifier(objective='binary', reg_lambda=10, n_estimators=10000)\n",
    "attack_model.fit(train_feature, train_label)\n",
    "predict = attack_model.predict(test_feature)\n",
    "precision_general, recall_general, _, _ = precision_recall_fscore_support(y_pred=predict,y_true=test_label,average=\"binary\")\n",
    "print('End fitting and predicting')\n",
    "print('- - - - - - - - - - - - - - - ')\n",
    "\n",
    "print('result')\n",
    "print('- - - - - - - - - - - - - - - ')\n",
    "print('precision: {:.5f}'.format(precision_general))\n",
    "print('recall: {:.5f}'.format(recall_general))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA38OaGBzt8J"
   },
   "source": [
    "#### *Attack model 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_WW2lz_1AO0"
   },
   "source": [
    "Result is not good. Need more tuning or trick. Guess one possible way is to do some transforms on feature vectors such as log. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_EdeM1_i9n4"
   },
   "source": [
    "##### *Define a MLP class for attack model 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1646131066760,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "1zaZadq_i5vp"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "        # 3 features, thus input size=3\n",
    "        # Yes or no, and use sigmoid thus output size=1\n",
    "        # If use softmax, output size = 2\n",
    "        # Loss: cross entropy has contained softmax \n",
    "    def __init__(self, num_of_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_of_features, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x,dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVp3m5Cjck1_"
   },
   "source": [
    "##### *Functions for training and evaluating (attack model 2)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1646131066760,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "bz5VpXofNe4D"
   },
   "outputs": [],
   "source": [
    "def attack_train(model, dataloader, criterion, opt):\n",
    "    running_loss = 0\n",
    "    # switch to model:train\n",
    "    # no difference here since no dropout and BN\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        opt.zero_grad()\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predict = model(imgs)\n",
    "        #print(predict.dtype)\n",
    "        #print(labels.dtype)\n",
    "        labels = torch.flatten(labels.long())\n",
    "        #print(predict.shape,labels.shape)\n",
    "        #print(predict)\n",
    "        #print(labels)\n",
    "        loss = criterion(predict, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        count = i\n",
    "        running_loss += loss\n",
    "    return running_loss / count\n",
    "\n",
    "def attack_evaluation(model, dataloader, batch_size=64):\n",
    "    # switch to model:eval\n",
    "    # no difference here since no dropout and BN    \n",
    "    model.eval()\n",
    "    # y_tensorlist is a list consists of some tensors\n",
    "    y_true_tensorlist = []\n",
    "    y_predict_tensorlist = []\n",
    "    for step, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        batch_y = torch.flatten(batch_y)\n",
    "        output = model(batch_x)\n",
    "        #output = F.softmax(output,dim=-1)\n",
    "        #print(output)\n",
    "        # compare cols\n",
    "        batch_y_predict = torch.argmax(output, dim=1)\n",
    "        #print(output)        \n",
    "        #zero = torch.zeros_like(output)\n",
    "        #one = torch.ones_like(output)\n",
    "        #batch_y_predict = torch.where(output > 0.5, one, zero)\n",
    "        #print(batch_y_predict)\n",
    "        #print(batch_y_predict)\n",
    "        y_predict_tensorlist.append(batch_y_predict)        \n",
    "        y_true_tensorlist.append(batch_y)\n",
    "        \n",
    "    # combine the tensors in the list into one\n",
    "    y_true = torch.cat(y_true_tensorlist,0)\n",
    "    y_predict = torch.cat(y_predict_tensorlist,0)\n",
    "\n",
    "    # compute accuracy\n",
    "    length = len(y_true)\n",
    "    right_length = torch.sum(y_true == y_predict)\n",
    "    #print(right_length/length)\n",
    "    \n",
    "    return right_length/length,y_true,y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01pnq0c-cuzU"
   },
   "source": [
    "##### *Train attack model 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18625,
     "status": "ok",
     "timestamp": 1646131085369,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "jl-WRwC4DFyY",
    "outputId": "dfd472b2-e751-41ff-ebe4-ed4ee22b657f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1052.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1   loss: 0.69482  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1027.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2   loss: 0.69456  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1059.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3   loss: 0.69448  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1049.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4   loss: 0.69445  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1108.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5   loss: 0.69445  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1066.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6   loss: 0.69444  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1063.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7   loss: 0.69443  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1098.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8   loss: 0.69443  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1067.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch9   loss: 0.69442  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1066.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10   loss: 0.69442  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1031.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch11   loss: 0.69442  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1068.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch12   loss: 0.69441  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1090.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch13   loss: 0.69441  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1066.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch14   loss: 0.69440  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1057.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch15   loss: 0.69440  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1056.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch16   loss: 0.69440  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1074.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch17   loss: 0.69439  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1039.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch18   loss: 0.69439  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1076.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch19   loss: 0.69438  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1068.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch20   loss: 0.69438  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1083.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch21   loss: 0.69437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1076.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch22   loss: 0.69437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1060.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch23   loss: 0.69437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1098.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch24   loss: 0.69436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1068.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch25   loss: 0.69436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1096.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch26   loss: 0.69435  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1056.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch27   loss: 0.69435  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1081.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch28   loss: 0.69434  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1080.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch29   loss: 0.69434  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1062.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch30   loss: 0.69434  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1068.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch31   loss: 0.69433  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1063.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch32   loss: 0.69433  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1058.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch33   loss: 0.69433  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1018.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch34   loss: 0.69432  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1047.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch35   loss: 0.69432  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1061.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch36   loss: 0.69431  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1077.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch37   loss: 0.69431  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1074.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch38   loss: 0.69431  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1053.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch39   loss: 0.69430  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 1056.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch40   loss: 0.69430  \n"
     ]
    }
   ],
   "source": [
    "# no gpu, thus device is only cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train attack\n",
    "attack = MLP(num_of_features=3).to(device)\n",
    "# settings\n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(attack.parameters(), lr=0.00001)\n",
    "epoch = 40\n",
    "train_attack_dataloader = DataLoader(dataset=train_attack, batch_size=64, shuffle = True)\n",
    "test_attack_dataloader = DataLoader(dataset=test_attack, batch_size=64, shuffle = True)\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = attack_train(attack, train_attack_dataloader, criterion, opt)\n",
    "    print(\"epoch%d   loss: %.5f  \"\\\n",
    "      % (i+1, loss_train))\n",
    "torch.save(attack.state_dict(), \"./models/attack_MNIST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1646131085719,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "CzUcoAtnk-Ti"
   },
   "outputs": [],
   "source": [
    "_,y_true,y_predict = attack_evaluation(attack, test_attack_dataloader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646131085719,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "yXFxqBgypIX-",
    "outputId": "4baefcd7-3ec3-491e-949f-96eeb3a526f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5039650371832376"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646131085720,
     "user": {
      "displayName": "储俊杰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15711395732155443147"
     },
     "user_tz": -60
    },
    "id": "0MMSxwNT3CM-",
    "outputId": "73c044a9-e7d4-46e6-e211-d16a270f596d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_leak_1st_attack_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
