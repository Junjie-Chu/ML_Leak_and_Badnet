{"cells":[{"cell_type":"markdown","id":"ae1ace01","metadata":{"id":"ae1ace01"},"source":["# ***This is a simple implement of basic 1st attack introduced in ML-leak article on MNIST***"]},{"cell_type":"markdown","source":["## ***General setting code***"],"metadata":{"id":"Fh5n0HDmt7ex"},"id":"Fh5n0HDmt7ex"},{"cell_type":"markdown","id":"9faa6e17","metadata":{"id":"9faa6e17"},"source":["### ***Install all independency here***"]},{"cell_type":"code","execution_count":1,"id":"4e05b969","metadata":{"id":"4e05b969","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646125952691,"user_tz":-60,"elapsed":59272,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"cdbde99d-5eb4-4709-d0cc-337578b95566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n","Collecting torch==1.10.2+cpu\n","  Downloading https://download.pytorch.org/whl/cpu/torch-1.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (199.3 MB)\n","\u001b[K     |████████████████████████████████| 199.3 MB 2.1 MB/s \n","\u001b[?25hCollecting torchvision==0.11.3+cpu\n","  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.11.3%2Bcpu-cp37-cp37m-linux_x86_64.whl (16.1 MB)\n","\u001b[K     |████████████████████████████████| 16.1 MB 85.6 MB/s \n","\u001b[?25hCollecting torchaudio==0.10.2+cpu\n","  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.10.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n","\u001b[K     |████████████████████████████████| 2.7 MB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.2+cpu) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (1.21.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cpu) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cpu which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.2+cpu torchaudio-0.10.2+cpu torchvision-0.11.3+cpu\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.5)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.2)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.2)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.11.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.10.0.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.7)\n","Enabling notebook extension jupyter-js-widgets/extension...\n","      - Validating: \u001b[32mOK\u001b[0m\n"]}],"source":["!pip3 install torch==1.10.2+cpu torchvision==0.11.3+cpu torchaudio==0.10.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n","!pip3 install ipywidgets\n","!jupyter nbextension enable --py widgetsnbextension"]},{"cell_type":"markdown","id":"ead3c117","metadata":{"id":"ead3c117"},"source":["### ***Import all dependency here***"]},{"cell_type":"code","execution_count":1,"id":"bcfb973c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcfb973c","executionInfo":{"status":"ok","timestamp":1646130693629,"user_tz":-60,"elapsed":23185,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"e03953aa-abaf-4930-cdd9-87730895ba3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# to monitor the progress\n","from tqdm import tqdm\n","import time\n","# basic dependency\n","import numpy as np\n","import random\n","# pytorch related\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","from torch import optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","# for visulization\n","import matplotlib.pyplot as plt\n","from random import shuffle\n","# sklearn\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","# other classifier\n","import lightgbm as lgb\n","# for mount from Colab to my drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/My Drive')"]},{"cell_type":"markdown","source":["## ***Target and shadow model code***"],"metadata":{"id":"DEedWF9OumTa"},"id":"DEedWF9OumTa"},{"cell_type":"markdown","id":"6d71553e","metadata":{"id":"6d71553e"},"source":["### ***Define a Neural Network class for shadow and target model***"]},{"cell_type":"code","execution_count":2,"id":"3fb175d0","metadata":{"id":"3fb175d0","executionInfo":{"status":"ok","timestamp":1646130703690,"user_tz":-60,"elapsed":250,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"outputs":[],"source":["# reuse the NN in badnet\n","class basicNet(nn.Module):\n","\n","    def __init__(self,inputchannels,outputclasses):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(inputchannels, 16, 5)\n","        self.conv2 = nn.Conv2d(16, 32, 5)\n","        self.pool = nn.AvgPool2d(2)\n","        if inputchannels == 3:\n","          inputfeatures = 800\n","        else:\n","          inputfeatures = 512\n","        self.fc1 = nn.Linear(inputfeatures, 512)\n","        self.fc2 = nn.Linear(512, outputclasses)\n","\n","    def forward(self, x):\n","        # conv block1\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # conv block2\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # reshape(flat) the feature to be the input of full connect layer\n","        x = x.view(-1, self.num_features(x))\n","        # fc block1\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        # fc block2\n","        x = self.fc2(x)\n","        x = F.softmax(x,dim=-1)\n","        return x\n","\n","    def num_features(self, x):\n","        # size of different dimensions\n","        size_D = x.size()[1:]\n","        total = 1\n","        for i in size_D:\n","            total = total*i\n","        return total"]},{"cell_type":"markdown","id":"7a252906","metadata":{"id":"7a252906"},"source":["### ***Functions for training and evaluating(target/shadow model)***"]},{"cell_type":"code","execution_count":3,"id":"13fc66e9","metadata":{"id":"13fc66e9","executionInfo":{"status":"ok","timestamp":1646130703957,"user_tz":-60,"elapsed":3,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"outputs":[],"source":["def train(model, dataloader, criterion, opt):\n","    running_loss = 0\n","    # switch to model:train\n","    # no difference here since no dropout and BN\n","    model.train()\n","    count = 0\n","    for i, data in tqdm(enumerate(dataloader)):\n","        opt.zero_grad()\n","        imgs, labels = data\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        predict = model(imgs)\n","        #print(predict.dtype)\n","        #print(labels.dtype)\n","        loss = criterion(predict, labels)\n","        loss.backward()\n","        opt.step()\n","        count = i\n","        running_loss += loss\n","    return running_loss / count\n","\n","\n","def evaluation(model, dataloader, batch_size=64):\n","    # switch to model:eval\n","    # no difference here since no dropout and BN    \n","    model.eval()\n","    # y_tensorlist is a list consists of some tensors\n","    y_true_tensorlist = []\n","    y_predict_tensorlist = []\n","    for step, (batch_x, batch_y) in enumerate(dataloader):\n","        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n","        output = model(batch_x)\n","        #print(output.shape)\n","        batch_y_predict = torch.argmax(output, dim=1)\n","        \n","        y_predict_tensorlist.append(batch_y_predict)\n","        \n","        y_true_tensorlist.append(batch_y)\n","        \n","    # combine the tensors in the list into one\n","    y_true = torch.cat(y_true_tensorlist,0)\n","    y_predict = torch.cat(y_predict_tensorlist,0)\n","\n","    # compute accuracy\n","    length = len(y_true)\n","    right_length = torch.sum(y_true == y_predict)\n","    #print(right_length/length)\n","    \n","    return right_length/length"]},{"cell_type":"markdown","source":["## ***Attack model's dataset code***"],"metadata":{"id":"_nlM-pvGTSft"},"id":"_nlM-pvGTSft"},{"cell_type":"markdown","source":["### ***Functions used to create attack model's dataset***"],"metadata":{"id":"t5w08voru7pz"},"id":"t5w08voru7pz"},{"cell_type":"code","source":["def attackdataset_x_1_batch(shadow,batch_x,device):\n","    shadow.eval()\n","    # Aim to get features(x)\n","    # output of model shadow is probabilities\n","    batch_y = shadow(batch_x.to(device))\n","    sorted_prob,_ = torch.sort(batch_y,descending=True)\n","    #print(sorted_prob.shape)\n","\n","    # choose 3 highest probabilities as feature vector\n","    # This is a batch's output, not single image.\n","    # feature: x, x is already a tensor\n","    feature_vectors = torch.narrow(sorted_prob,dim=1,start=0,length=3)\n","\n","    return feature_vectors\n","\n","def get_attackdataset(shadow,train_loader,out_loader,device):\n","    shadow.eval()\n","    # 1. get a tensor list of x\n","    # 2. combine all tensors in tensor list x into a tensor X\n","    # 3. generate label tensor Y, the length is the same as X\n","    attack_set=[]\n","\n","    attack_X_train_list = []\n","    for i, (batch_x, batch_y) in enumerate(train_loader):\n","        batch_x = batch_x.to(device)\n","        batch_y = batch_y.to(device)\n","        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n","        attack_X_train_list.append(feature_vectors)\n","    attack_X_train = torch.cat(attack_X_train_list,0)\n","    for i in attack_X_train:\n","      attack_set.append((i.detach(),torch.ones(1)))\n","\n","    # train:label = 1\n","    #attack_Y_train = torch.ones(attack_X_train.shape[0])\n","    #print('attack Y train shape: ',attack_Y_train.shape)\n","\n","    attack_X_out_list = []\n","    for i, (batch_x, batch_y) in enumerate(out_loader):\n","        feature_vectors = attackdataset_x_1_batch(shadow,batch_x,device=device)\n","        attack_X_out_list.append(feature_vectors)\n","    attack_X_out = torch.cat(attack_X_out_list,0)\n","    for i in attack_X_out:\n","      attack_set.append((i.detach(),torch.zeros(1)))\n","    # out: label = 0\n","    #attack_Y_out = torch.zeros(attack_X_out.shape[0])\n","    #print('attack Y out shape: ',attack_Y_out.shape)\n","\n","    # combine train and out to get the whole dataset's X and Y\n","    #attack_X = torch.cat([attack_X_train,attack_X_out],0)\n","    #attack_Y = torch.cat([attack_Y_train,attack_Y_out],0)\n","    #print('attack X total shape: ',attack_X.shape)\n","    #return attack_X.detach(),attack_Y\n","    shuffle(attack_set)\n","    print(attack_set[0])\n","    return attack_set"],"metadata":{"id":"G2I1HeglTt-y","executionInfo":{"status":"ok","timestamp":1646130704967,"user_tz":-60,"elapsed":253,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"id":"G2I1HeglTt-y","execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### ***Define attack model's dataset class***"],"metadata":{"id":"lbW2B9MH32bc"},"id":"lbW2B9MH32bc"},{"cell_type":"code","source":["class attack_dataset(Dataset):\n","    # N data points, features include N top 3 probabilities, labels include N labels(1/0)\n","    # elements in features and labels are already tensor.\n","    def __init__(self, attack_set, transform = None, device=torch.device(\"cpu\")):\n","        self.attack_set = attack_set\n","        self.device = device\n","        self.transform = transform\n","\n","    def __getitem__(self, item):\n","        # extract x,y , x,y are all tensors\n","        x = self.attack_set[item][0]\n","        y = self.attack_set[item][1]\n","        # send x,y to device\n","        x = x.to(self.device)\n","        y = y.to(self.device)\n","        \n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.attack_set)"],"metadata":{"id":"qTBHu9vf31pL","executionInfo":{"status":"ok","timestamp":1646130704968,"user_tz":-60,"elapsed":3,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"id":"qTBHu9vf31pL","execution_count":5,"outputs":[]},{"cell_type":"markdown","id":"11e939a8","metadata":{"id":"11e939a8"},"source":["## ***Main part***"]},{"cell_type":"markdown","source":["### ***MNIST***"],"metadata":{"id":"WGB65vV3J39-"},"id":"WGB65vV3J39-"},{"cell_type":"markdown","source":["#### *Download, split and load data*"],"metadata":{"id":"s4m6DkJVeKw3"},"id":"s4m6DkJVeKw3"},{"cell_type":"code","execution_count":9,"id":"563a1486","metadata":{"id":"563a1486","executionInfo":{"status":"ok","timestamp":1646130727303,"user_tz":-60,"elapsed":236,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"outputs":[],"source":["# prepare original data\n","transforms = T.Compose([T.ToTensor(),T.Normalize((0.1307,), (0.3081,))])\n","train_data_MNIST = datasets.MNIST(root=\"./data_1/\", train=True,transform=transforms, download=True)\n","test_data_MNIST = datasets.MNIST(root=\"./data_1/\",train=False,transform=transforms, download=True)"]},{"cell_type":"code","source":["# set the length of each split\n","length_train_data_MNIST = len(train_data_MNIST)\n","lengthlist = [int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST),int(0.25*length_train_data_MNIST)]\n","print(length_train_data_MNIST)\n","print(lengthlist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmKZJtProrf0","executionInfo":{"status":"ok","timestamp":1646130727611,"user_tz":-60,"elapsed":3,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"f4cf0ac8-adf9-43ef-cde6-43c43b9aceca"},"id":"lmKZJtProrf0","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["60000\n","[15000, 15000, 15000, 15000]\n"]}]},{"cell_type":"code","execution_count":11,"id":"5db0677d","metadata":{"id":"5db0677d","executionInfo":{"status":"ok","timestamp":1646130727611,"user_tz":-60,"elapsed":2,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"outputs":[],"source":["# MNIST\n","# split the dataset into 4 part: target train/out, shadow train/out\n","train_target_dataset_MNIST,out_target_dataset_MNIST,train_shadow_dataset_MNIST,out_shadow_dataset_MNIST = random_split(\n","    dataset=train_data_MNIST,\n","    lengths=lengthlist,\n","    generator=torch.Generator().manual_seed(19260817)\n",")\n","# This is the main dataloader with the total dataset\n","target_train_loader = DataLoader(dataset=train_target_dataset_MNIST, batch_size=64, shuffle = True)\n","target_out_loader = DataLoader(dataset=out_target_dataset_MNIST, batch_size=64, shuffle = True)\n","\n","shadow_train_loader = DataLoader(dataset=train_shadow_dataset_MNIST, batch_size=64, shuffle = True)\n","shadow_out_loader = DataLoader(dataset=out_shadow_dataset_MNIST, batch_size=64, shuffle = True)\n","\n","testloader = DataLoader(dataset=test_data_MNIST, batch_size=64, shuffle = True)\n"]},{"cell_type":"markdown","source":["#### *Pretrain target and shadow models*"],"metadata":{"id":"UxsZSRDMX4Km"},"id":"UxsZSRDMX4Km"},{"cell_type":"code","source":["# use train_target to train target model\n","# no gpu, thus device is only cpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Train target\n","# load model\n","# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n","# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n","target = basicNet(inputchannels=1, outputclasses=10).to(device)\n","# settings\n","criterion = nn.CrossEntropyLoss()\n","sgd = optim.SGD(target.parameters(), lr=0.01, momentum=0.9)\n","epoch = 20\n","\n","# train\n","print(\"start training: \")\n","for i in range(epoch):\n","    loss_train = train(target, target_train_loader, criterion, sgd)\n","# Acc\n","acc_train = evaluation(target, target_train_loader, batch_size=64)\n","acc_test = evaluation(target, testloader, batch_size=64)\n","print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n","      % (epoch, loss_train, acc_train, acc_test))\n","torch.save(target.state_dict(), \"./models/target_MNIST.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o87ufHdBvU1o","executionInfo":{"status":"ok","timestamp":1646126173271,"user_tz":-60,"elapsed":160208,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"7e1f6fcf-33b5-4538-c441-17c19c175490"},"id":"o87ufHdBvU1o","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["start training: \n"]},{"output_type":"stream","name":"stderr","text":["235it [00:07, 30.75it/s]\n","235it [00:07, 31.36it/s]\n","235it [00:07, 30.80it/s]\n","235it [00:08, 26.34it/s]\n","235it [00:07, 30.70it/s]\n","235it [00:07, 30.86it/s]\n","235it [00:07, 30.34it/s]\n","235it [00:07, 30.99it/s]\n","235it [00:08, 28.55it/s]\n","235it [00:07, 31.13it/s]\n","235it [00:07, 31.32it/s]\n","235it [00:07, 31.10it/s]\n","235it [00:07, 30.96it/s]\n","235it [00:07, 31.42it/s]\n","235it [00:07, 31.36it/s]\n","235it [00:07, 31.34it/s]\n","235it [00:07, 31.11it/s]\n","235it [00:07, 30.83it/s]\n","235it [00:07, 31.14it/s]\n","235it [00:07, 30.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch20   loss: 1.48706  training accuracy: 0.98247  testing accuracy: 0.97420\n"]}]},{"cell_type":"code","source":["# use train_shadow to train shadow model\n","# no gpu, thus device is only cpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Train shadow\n","# load model\n","# if use MNIST, inputchannels=1, if use CIFAR10, inputchannels=3, both output classes = 10\n","# related info could be get by using input_channels=train_data_loader.dataset.channels, output_num=train_data_loader.dataset.class_num\n","shadow = basicNet(inputchannels=1, outputclasses=10).to(device)\n","# settings\n","criterion = nn.CrossEntropyLoss()\n","sgd = optim.SGD(shadow.parameters(), lr=0.01, momentum=0.9)\n","epoch = 20\n","\n","# train\n","print(\"start training: \")\n","for i in range(epoch):\n","    loss_train = train(shadow, shadow_train_loader, criterion, sgd)\n","# Acc\n","acc_train = evaluation(shadow, shadow_train_loader, batch_size=64)\n","acc_test = evaluation(shadow, testloader, batch_size=64)\n","print(\"epoch%d   loss: %.5f  training accuracy: %.5f  testing accuracy: %.5f\"\\\n","      % (epoch, loss_train, acc_train, acc_test))\n","torch.save(shadow.state_dict(), \"./models/shadow_MNIST.pth\")"],"metadata":{"id":"-C08BexDw0Za","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646126447144,"user_tz":-60,"elapsed":175853,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"43f48175-db84-44ca-c8cd-d512722df62e"},"id":"-C08BexDw0Za","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["start training: \n"]},{"output_type":"stream","name":"stderr","text":["235it [00:07, 31.46it/s]\n","235it [00:07, 31.31it/s]\n","235it [00:07, 31.30it/s]\n","235it [00:07, 31.29it/s]\n","235it [00:07, 31.12it/s]\n","235it [00:07, 31.53it/s]\n","235it [00:07, 31.41it/s]\n","235it [00:07, 31.28it/s]\n","235it [00:08, 27.58it/s]\n","235it [00:07, 29.85it/s]\n","235it [00:13, 16.90it/s]\n","235it [00:09, 23.55it/s]\n","235it [00:08, 26.92it/s]\n","235it [00:07, 29.90it/s]\n","235it [00:09, 24.84it/s]\n","235it [00:09, 24.92it/s]\n","235it [00:07, 30.02it/s]\n","235it [00:07, 30.60it/s]\n","235it [00:09, 24.48it/s]\n","235it [00:07, 29.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch20   loss: 1.48643  training accuracy: 0.98620  testing accuracy: 0.97560\n"]}]},{"cell_type":"markdown","source":["#### *Load pretrained target and shadow models (to save time)*"],"metadata":{"id":"7h_K6vlPYDNi"},"id":"7h_K6vlPYDNi"},{"cell_type":"code","source":["# no gpu, thus device is only cpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# load pretrained model\n","target_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n","# if gpu, remove map_location=torch.device('cpu')\n","target_pre.load_state_dict(torch.load(\"./models/target_MNIST.pth\",map_location=torch.device('cpu')))\n","target_pre.eval()\n","shadow_pre = basicNet(inputchannels=1, outputclasses=10).to(device)\n","# if gpu, remove map_location=torch.device('cpu')\n","shadow_pre.load_state_dict(torch.load(\"./models/shadow_MNIST.pth\",map_location=torch.device('cpu')))\n","shadow_pre.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrhBkmQGKH6b","executionInfo":{"status":"ok","timestamp":1646130734908,"user_tz":-60,"elapsed":2086,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"2ce49678-4b38-4da4-a039-653b4e666b4c"},"id":"NrhBkmQGKH6b","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["basicNet(\n","  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc1): Linear(in_features=512, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# test if these models are loaded\n","acc_test1 = evaluation(target_pre, testloader, batch_size=64)\n","print(acc_test1)\n","acc_test2 = evaluation(shadow_pre, testloader, batch_size=4)\n","print(acc_test2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6to48RLPQ--x","executionInfo":{"status":"ok","timestamp":1646130739863,"user_tz":-60,"elapsed":4958,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"2dfe6553-bea3-4cf7-8571-2f1465d9e21c"},"id":"6to48RLPQ--x","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9742)\n","tensor(0.9756)\n"]}]},{"cell_type":"code","source":["shadow = shadow_pre\n","target = target_pre"],"metadata":{"id":"CwIqIZUS8mF_","executionInfo":{"status":"ok","timestamp":1646130739863,"user_tz":-60,"elapsed":14,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"id":"CwIqIZUS8mF_","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["#### *Create dataset for attack model*"],"metadata":{"id":"N6VMvCKcaF9x"},"id":"N6VMvCKcaF9x"},{"cell_type":"code","source":["# 1. create train dataset for attack model\n","# use shadow model and dataset: out_shadow, train_shadow\n","print('Creating training dataset for attack model:')\n","train_attack_set = get_attackdataset(shadow,shadow_train_loader,shadow_out_loader,device=device)\n","train_attack = attack_dataset(attack_set=train_attack_set,device=device)\n","print('- - - - - - - - - - - - - - - - - - ')\n","print('Creating test dataset for attack model:')\n","# 2. create test dataset for attack model\n","# use target model and dataset: out_target, train_target\n","test_attack_set = get_attackdataset(target,target_train_loader,target_out_loader,device=device)\n","test_attack = attack_dataset(attack_set=test_attack_set,device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBjWSeKC6SiV","executionInfo":{"status":"ok","timestamp":1646130760530,"user_tz":-60,"elapsed":16579,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"0cae830c-d94c-4ec3-ab18-795e618ccbef"},"id":"jBjWSeKC6SiV","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training dataset for attack model:\n","(tensor([1.0000e+00, 4.1738e-08, 1.2873e-12]), tensor([0.]))\n","- - - - - - - - - - - - - - - - - - \n","Creating test dataset for attack model:\n","(tensor([1.0000e+00, 1.0961e-09, 1.0551e-09]), tensor([1.]))\n"]}]},{"cell_type":"markdown","source":["#### *Attack model 1* "],"metadata":{"id":"7Lq3iEDFzlUc"},"id":"7Lq3iEDFzlUc"},{"cell_type":"markdown","source":["##### *Prepare dataset for attack model 1: LGBMClassifier*"],"metadata":{"id":"3eCw5E-OyYaE"},"id":"3eCw5E-OyYaE"},{"cell_type":"code","source":["train_feature = []\n","train_label = []\n","for i in train_attack_set:\n","  train_feature.append(i[0].cpu().numpy())\n","  train_label.append(int(i[1]))\n","\n","test_feature = []\n","test_label = []\n","for i in test_attack_set:\n","  test_feature.append(i[0].cpu().numpy())\n","  test_label.append(int(i[1]))"],"metadata":{"id":"ytIcG63TnXve","executionInfo":{"status":"ok","timestamp":1646130788186,"user_tz":-60,"elapsed":222,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"id":"ytIcG63TnXve","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["##### *Attack model 1: LGBMClassifier and output*"],"metadata":{"id":"flHPKxCDysfW"},"id":"flHPKxCDysfW"},{"cell_type":"code","source":["attack_model = lgb.LGBMClassifier(objective='binary', reg_lambda=10, n_estimators=10000)\n","attack_model.fit(train_feature, train_label)\n","predict = attack_model.predict(test_feature)\n","precision_general, recall_general, _, _ = precision_recall_fscore_support(y_pred=predict,y_true=test_label,average=\"binary\")\n","print('End fitting and predicting')\n","print('- - - - - - - - - - - - - - - ')\n","\n","print('result')\n","print('- - - - - - - - - - - - - - - ')\n","print('precision: {:.5f}'.format(precision_general))\n","print('recall: {:.5f}'.format(recall_general))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnxQtLtTnYjt","executionInfo":{"status":"ok","timestamp":1646131066759,"user_tz":-60,"elapsed":51957,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"92dccd9e-9fa7-4867-c12d-cec11d554e38"},"id":"AnxQtLtTnYjt","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["End fitting and predicting\n","- - - - - - - - - - - - - - - \n","result\n","- - - - - - - - - - - - - - - \n","precision: 0.49924\n","recall: 0.50193\n"]}]},{"cell_type":"markdown","source":["#### *Attack model 2*"],"metadata":{"id":"lA38OaGBzt8J"},"id":"lA38OaGBzt8J"},{"cell_type":"markdown","source":["Result is not good. Need more tuning or trick. Guess one possible way is to do some transforms on feature vectors such as log. "],"metadata":{"id":"D_WW2lz_1AO0"},"id":"D_WW2lz_1AO0"},{"cell_type":"markdown","source":["##### *Define a MLP class for attack model 2*"],"metadata":{"id":"v_EdeM1_i9n4"},"id":"v_EdeM1_i9n4"},{"cell_type":"code","source":["class MLP(nn.Module):\n","        # 3 features, thus input size=3\n","        # Yes or no, and use sigmoid thus output size=1\n","        # If use softmax, output size = 2\n","        # Loss: cross entropy has contained softmax \n","    def __init__(self, num_of_features=3):\n","        super().__init__()\n","        self.fc1 = nn.Linear(num_of_features, 64)\n","        self.fc2 = nn.Linear(64, 2)\n","        #self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        # Hidden layer\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = F.softmax(x,dim=-1)\n","        return x"],"metadata":{"id":"1zaZadq_i5vp","executionInfo":{"status":"ok","timestamp":1646131066760,"user_tz":-60,"elapsed":17,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"execution_count":21,"outputs":[],"id":"1zaZadq_i5vp"},{"cell_type":"markdown","source":["##### *Functions for training and evaluating (attack model 2)*"],"metadata":{"id":"JVp3m5Cjck1_"},"id":"JVp3m5Cjck1_"},{"cell_type":"code","source":["def attack_train(model, dataloader, criterion, opt):\n","    running_loss = 0\n","    # switch to model:train\n","    # no difference here since no dropout and BN\n","    model.train()\n","    count = 0\n","    for i, data in tqdm(enumerate(dataloader)):\n","        opt.zero_grad()\n","        imgs, labels = data\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        predict = model(imgs)\n","        #print(predict.dtype)\n","        #print(labels.dtype)\n","        labels = torch.flatten(labels.long())\n","        #print(predict.shape,labels.shape)\n","        #print(predict)\n","        #print(labels)\n","        loss = criterion(predict, labels)\n","        loss.backward()\n","        opt.step()\n","        count = i\n","        running_loss += loss\n","    return running_loss / count\n","\n","def attack_evaluation(model, dataloader, batch_size=64):\n","    # switch to model:eval\n","    # no difference here since no dropout and BN    \n","    model.eval()\n","    # y_tensorlist is a list consists of some tensors\n","    y_true_tensorlist = []\n","    y_predict_tensorlist = []\n","    for step, (batch_x, batch_y) in enumerate(dataloader):\n","        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n","        batch_y = torch.flatten(batch_y)\n","        output = model(batch_x)\n","        #output = F.softmax(output,dim=-1)\n","        #print(output)\n","        # compare cols\n","        batch_y_predict = torch.argmax(output, dim=1)\n","        #print(output)        \n","        #zero = torch.zeros_like(output)\n","        #one = torch.ones_like(output)\n","        #batch_y_predict = torch.where(output > 0.5, one, zero)\n","        #print(batch_y_predict)\n","        #print(batch_y_predict)\n","        y_predict_tensorlist.append(batch_y_predict)        \n","        y_true_tensorlist.append(batch_y)\n","        \n","    # combine the tensors in the list into one\n","    y_true = torch.cat(y_true_tensorlist,0)\n","    y_predict = torch.cat(y_predict_tensorlist,0)\n","\n","    # compute accuracy\n","    length = len(y_true)\n","    right_length = torch.sum(y_true == y_predict)\n","    #print(right_length/length)\n","    \n","    return right_length/length,y_true,y_predict\n"],"metadata":{"id":"bz5VpXofNe4D","executionInfo":{"status":"ok","timestamp":1646131066760,"user_tz":-60,"elapsed":17,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"execution_count":22,"outputs":[],"id":"bz5VpXofNe4D"},{"cell_type":"markdown","source":["##### *Train attack model 2*"],"metadata":{"id":"01pnq0c-cuzU"},"id":"01pnq0c-cuzU"},{"cell_type":"code","source":["# no gpu, thus device is only cpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Train attack\n","attack = MLP(num_of_features=3).to(device)\n","# settings\n","#criterion = nn.BCELoss()\n","#criterion = nn.NLLLoss()\n","criterion = nn.CrossEntropyLoss()\n","opt = optim.Adam(attack.parameters(), lr=0.00001)\n","epoch = 40\n","train_attack_dataloader = DataLoader(dataset=train_attack, batch_size=64, shuffle = True)\n","test_attack_dataloader = DataLoader(dataset=test_attack, batch_size=64, shuffle = True)\n","# train\n","print(\"start training: \")\n","for i in range(epoch):\n","    loss_train = attack_train(attack, train_attack_dataloader, criterion, opt)\n","    print(\"epoch%d   loss: %.5f  \"\\\n","      % (i+1, loss_train))\n","torch.save(target.state_dict(), \"./models/attack_MNIST.pth\")"],"metadata":{"id":"jl-WRwC4DFyY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646131085369,"user_tz":-60,"elapsed":18625,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"dfd472b2-e751-41ff-ebe4-ed4ee22b657f"},"id":"jl-WRwC4DFyY","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["start training: \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1052.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch1   loss: 0.69482  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1027.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch2   loss: 0.69456  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1059.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch3   loss: 0.69448  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1049.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch4   loss: 0.69445  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1108.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch5   loss: 0.69445  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1066.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch6   loss: 0.69444  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1063.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch7   loss: 0.69443  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1098.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch8   loss: 0.69443  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1067.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch9   loss: 0.69442  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1066.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch10   loss: 0.69442  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1031.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch11   loss: 0.69442  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1068.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch12   loss: 0.69441  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1090.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch13   loss: 0.69441  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1066.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch14   loss: 0.69440  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1057.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch15   loss: 0.69440  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1056.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch16   loss: 0.69440  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1074.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch17   loss: 0.69439  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1039.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch18   loss: 0.69439  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1076.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch19   loss: 0.69438  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1068.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch20   loss: 0.69438  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1083.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch21   loss: 0.69437  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1076.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch22   loss: 0.69437  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1060.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch23   loss: 0.69437  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1098.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch24   loss: 0.69436  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1068.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch25   loss: 0.69436  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1096.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch26   loss: 0.69435  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1056.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch27   loss: 0.69435  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1081.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch28   loss: 0.69434  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1080.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch29   loss: 0.69434  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1062.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch30   loss: 0.69434  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1068.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch31   loss: 0.69433  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1063.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch32   loss: 0.69433  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1058.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch33   loss: 0.69433  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1018.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch34   loss: 0.69432  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1047.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch35   loss: 0.69432  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1061.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch36   loss: 0.69431  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1077.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch37   loss: 0.69431  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1074.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch38   loss: 0.69431  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1053.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch39   loss: 0.69430  \n"]},{"output_type":"stream","name":"stderr","text":["469it [00:00, 1056.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch40   loss: 0.69430  \n"]}]},{"cell_type":"code","source":["_,y_true,y_predict = attack_evaluation(attack, test_attack_dataloader, batch_size=64)"],"metadata":{"id":"CzUcoAtnk-Ti","executionInfo":{"status":"ok","timestamp":1646131085719,"user_tz":-60,"elapsed":364,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}}},"id":"CzUcoAtnk-Ti","execution_count":24,"outputs":[]},{"cell_type":"code","source":["precision_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXFxqBgypIX-","executionInfo":{"status":"ok","timestamp":1646131085719,"user_tz":-60,"elapsed":6,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"4baefcd7-3ec3-491e-949f-96eeb3a526f1"},"id":"yXFxqBgypIX-","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5039650371832376"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["recall_score(y_true.cpu().numpy(), y_predict.cpu().numpy(), average='binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MMSxwNT3CM-","executionInfo":{"status":"ok","timestamp":1646131085720,"user_tz":-60,"elapsed":6,"user":{"displayName":"储俊杰","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15711395732155443147"}},"outputId":"73c044a9-e7d4-46e6-e211-d16a270f596d"},"id":"0MMSxwNT3CM-","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9532666666666667"]},"metadata":{},"execution_count":26}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"ML_leak_1st_attack_MNIST.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}